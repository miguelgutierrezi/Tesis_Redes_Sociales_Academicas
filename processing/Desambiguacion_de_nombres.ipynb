{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-qt0bPsJr9i",
        "outputId": "e00db5ca-5a51-4994-e5e2-71525747f2b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95eB1cOXJdGe",
        "outputId": "a07460c0-230d-4de8-9083-cb2efd78b1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from fuzzywuzzy import fuzz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_authors():\n",
        "    documents = pd.read_csv('papersPreprocessed (2).csv')\n",
        "\n",
        "    authors_with_duplicates = []\n",
        "    print(\"Generando autores sin duplicados\")\n",
        "    for index, row in documents.iterrows():\n",
        "        authors_with_duplicates.extend(row['authorFull'].split(';'))\n",
        "\n",
        "    print(\"Autores generados\")\n",
        "\n",
        "    return list(set(authors_with_duplicates))"
      ],
      "metadata": {
        "id": "Si6_D0RDJx4z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ordenan los nombres y se ordenan alfabeticamente\n",
        "def normalize_name(name):\n",
        "    name_parts = name.split()\n",
        "    name_parts = [part.strip(' .,') for part in name_parts]\n",
        "    return ' '.join(sorted(name_parts)).lower()"
      ],
      "metadata": {
        "id": "vqB-hklIJ65F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A partir de clusterización con fuzzybuzz, se valida la distancia de Levenshtein y genera clusters de nombres similares\n",
        "def cluster_names(names, threshold=90):\n",
        "    print(\"Clusterizando nombres\")\n",
        "    normalized_names = [normalize_name(name) for name in names]\n",
        "    clusters = []\n",
        "\n",
        "    for name, norm_name in zip(names, normalized_names):\n",
        "        for cluster in clusters:\n",
        "            if fuzz.token_set_ratio(cluster[0], norm_name) >= threshold:\n",
        "                cluster.append(name)\n",
        "                break\n",
        "        else:\n",
        "            clusters.append([name])\n",
        "\n",
        "    print(\"Clusterización finalizada\")\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "cPz2MNYfJ8Zo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Genera el diccionario de nombres desambiguados, usando como llave, el nombre más corto\n",
        "def create_disambiguated_dict(names_clusters):\n",
        "    print(\"Generando diccionario\")\n",
        "    disambiguated_dict = {}\n",
        "\n",
        "    for cluster in names_clusters:\n",
        "        representative_name = sorted(cluster, key=len)[0]\n",
        "        disambiguated_dict[representative_name] = cluster\n",
        "\n",
        "    print(\"Diccionario generado\")\n",
        "    return disambiguated_dict"
      ],
      "metadata": {
        "id": "esfzJBS1J_Lv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file(authors_dict):\n",
        "    with open('authors_test.txt', 'w') as file:\n",
        "        json.dump(authors_dict, file)"
      ],
      "metadata": {
        "id": "0R6EOpoTKANn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = load_authors()\n",
        "\n",
        "print(\"Iniciando desambiguación\")\n",
        "names_clusters = cluster_names(authors)\n",
        "print(len(names_clusters))\n",
        "disambiguated_dict = create_disambiguated_dict(names_clusters)\n",
        "print(\"Autores desambiguados\")\n",
        "\n",
        "generate_file(disambiguated_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMN1XtbBKB4l",
        "outputId": "90127098-a317-480e-ad61-925ff8daf390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando autores sin duplicados\n",
            "Autores generados\n",
            "Iniciando desambiguación\n",
            "Clusterizando nombres\n"
          ]
        }
      ]
    }
  ]
}